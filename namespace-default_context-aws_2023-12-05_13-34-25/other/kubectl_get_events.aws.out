LAST SEEN   TYPE      REASON                    OBJECT                                                     MESSAGE
18m         Warning   FailedScheduling          pod/certmanager-cert-manager-5f77cf4598-rgjh2              no nodes available to schedule pods
13m         Warning   FailedScheduling          pod/certmanager-cert-manager-5f77cf4598-rgjh2              0/1 nodes are available: 1 node(s) had untolerated taint {node.cloudprovider.kubernetes.io/uninitialized: true}. preemption: 0/1 nodes are available: 1 Preemption is not helpful for scheduling..
13m         Normal    Scheduled                 pod/certmanager-cert-manager-5f77cf4598-rgjh2              Successfully assigned default/certmanager-cert-manager-5f77cf4598-rgjh2 to ip-10-0-188-41.us-east-2.compute.internal
13m         Normal    Pulling                   pod/certmanager-cert-manager-5f77cf4598-rgjh2              Pulling image "quay.io/jetstack/cert-manager-controller:v1.11.1"
13m         Normal    Pulled                    pod/certmanager-cert-manager-5f77cf4598-rgjh2              Successfully pulled image "quay.io/jetstack/cert-manager-controller:v1.11.1" in 5.598639627s (5.59865069s including waiting)
13m         Normal    Created                   pod/certmanager-cert-manager-5f77cf4598-rgjh2              Created container cert-manager-controller
13m         Normal    Started                   pod/certmanager-cert-manager-5f77cf4598-rgjh2              Started container cert-manager-controller
17m         Warning   FailedScheduling          pod/certmanager-cert-manager-cainjector-558bf5b55d-f2bx5   no nodes available to schedule pods
13m         Warning   FailedScheduling          pod/certmanager-cert-manager-cainjector-558bf5b55d-f2bx5   0/1 nodes are available: 1 node(s) had untolerated taint {node.cloudprovider.kubernetes.io/uninitialized: true}. preemption: 0/1 nodes are available: 1 Preemption is not helpful for scheduling..
13m         Normal    Scheduled                 pod/certmanager-cert-manager-cainjector-558bf5b55d-f2bx5   Successfully assigned default/certmanager-cert-manager-cainjector-558bf5b55d-f2bx5 to ip-10-0-188-41.us-east-2.compute.internal
13m         Normal    Pulling                   pod/certmanager-cert-manager-cainjector-558bf5b55d-f2bx5   Pulling image "quay.io/jetstack/cert-manager-cainjector:v1.11.1"
13m         Normal    Pulled                    pod/certmanager-cert-manager-cainjector-558bf5b55d-f2bx5   Successfully pulled image "quay.io/jetstack/cert-manager-cainjector:v1.11.1" in 4.953052043s (4.953152143s including waiting)
13m         Normal    Created                   pod/certmanager-cert-manager-cainjector-558bf5b55d-f2bx5   Created container cert-manager-cainjector
13m         Normal    Started                   pod/certmanager-cert-manager-cainjector-558bf5b55d-f2bx5   Started container cert-manager-cainjector
17m         Warning   FailedScheduling          pod/certmanager-cert-manager-webhook-74b6ddbb48-hjh5x      no nodes available to schedule pods
13m         Warning   FailedScheduling          pod/certmanager-cert-manager-webhook-74b6ddbb48-hjh5x      0/1 nodes are available: 1 node(s) had untolerated taint {node.cloudprovider.kubernetes.io/uninitialized: true}. preemption: 0/1 nodes are available: 1 Preemption is not helpful for scheduling..
13m         Normal    Scheduled                 pod/certmanager-cert-manager-webhook-74b6ddbb48-hjh5x      Successfully assigned default/certmanager-cert-manager-webhook-74b6ddbb48-hjh5x to ip-10-0-188-41.us-east-2.compute.internal
13m         Normal    Pulling                   pod/certmanager-cert-manager-webhook-74b6ddbb48-hjh5x      Pulling image "quay.io/jetstack/cert-manager-webhook:v1.11.1"
13m         Normal    Pulled                    pod/certmanager-cert-manager-webhook-74b6ddbb48-hjh5x      Successfully pulled image "quay.io/jetstack/cert-manager-webhook:v1.11.1" in 5.772368414s (5.772437718s including waiting)
13m         Normal    Created                   pod/certmanager-cert-manager-webhook-74b6ddbb48-hjh5x      Created container cert-manager-webhook
13m         Normal    Started                   pod/certmanager-cert-manager-webhook-74b6ddbb48-hjh5x      Started container cert-manager-webhook
17m         Warning   FailedScheduling          pod/coordinator-9b999cd76-t8sx6                            no nodes available to schedule pods
13m         Warning   FailedScheduling          pod/coordinator-9b999cd76-t8sx6                            0/1 nodes are available: 1 node(s) had untolerated taint {node.cloudprovider.kubernetes.io/uninitialized: true}. preemption: 0/1 nodes are available: 1 Preemption is not helpful for scheduling..
13m         Normal    Scheduled                 pod/coordinator-9b999cd76-t8sx6                            Successfully assigned default/coordinator-9b999cd76-t8sx6 to ip-10-0-185-3.us-east-2.compute.internal
13m         Normal    Pulling                   pod/coordinator-9b999cd76-t8sx6                            Pulling image "harbor.starburstdata.net/starburstdata/starburst-enterprise-init:1.5.2"
13m         Normal    Pulled                    pod/coordinator-9b999cd76-t8sx6                            Successfully pulled image "harbor.starburstdata.net/starburstdata/starburst-enterprise-init:1.5.2" in 8.765502293s (8.765514133s including waiting)
13m         Normal    Created                   pod/coordinator-9b999cd76-t8sx6                            Created container starburst-enterprise-init
13m         Normal    Started                   pod/coordinator-9b999cd76-t8sx6                            Started container starburst-enterprise-init
12m         Normal    Pulling                   pod/coordinator-9b999cd76-t8sx6                            Pulling image "harbor.starburstdata.net/starburstdata/starburst-enterprise:423-e.1"
12m         Normal    Pulled                    pod/coordinator-9b999cd76-t8sx6                            Successfully pulled image "harbor.starburstdata.net/starburstdata/starburst-enterprise:423-e.1" in 42.171760624s (42.171770415s including waiting)
10m         Normal    Created                   pod/coordinator-9b999cd76-t8sx6                            Created container coordinator
10m         Normal    Started                   pod/coordinator-9b999cd76-t8sx6                            Started container coordinator
12m         Warning   Unhealthy                 pod/coordinator-9b999cd76-t8sx6                            Startup probe failed: Get "http://10.0.186.177:8080/v1/readiness": dial tcp 10.0.186.177:8080: connect: connection refused
10m         Warning   Unhealthy                 pod/coordinator-9b999cd76-t8sx6                            Startup probe failed: Get "http://10.0.186.177:8080/v1/readiness": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
10m         Warning   Unhealthy                 pod/coordinator-9b999cd76-t8sx6                            Startup probe failed: HTTP probe failed with statuscode: 503
10m         Normal    Pulled                    pod/coordinator-9b999cd76-t8sx6                            Container image "harbor.starburstdata.net/starburstdata/starburst-enterprise:423-e.1" already present on machine
17m         Warning   FailedScheduling          pod/externaldns-external-dns-656c894cb-bl822               no nodes available to schedule pods
13m         Warning   FailedScheduling          pod/externaldns-external-dns-656c894cb-bl822               0/1 nodes are available: 1 node(s) had untolerated taint {node.cloudprovider.kubernetes.io/uninitialized: true}. preemption: 0/1 nodes are available: 1 Preemption is not helpful for scheduling..
13m         Normal    Scheduled                 pod/externaldns-external-dns-656c894cb-bl822               Successfully assigned default/externaldns-external-dns-656c894cb-bl822 to ip-10-0-188-41.us-east-2.compute.internal
13m         Normal    Pulling                   pod/externaldns-external-dns-656c894cb-bl822               Pulling image "docker.io/bitnami/external-dns:0.13.4-debian-11-r2"
12m         Normal    Pulled                    pod/externaldns-external-dns-656c894cb-bl822               Successfully pulled image "docker.io/bitnami/external-dns:0.13.4-debian-11-r2" in 11.177605346s (11.177617179s including waiting)
12m         Normal    Created                   pod/externaldns-external-dns-656c894cb-bl822               Created container external-dns
12m         Normal    Started                   pod/externaldns-external-dns-656c894cb-bl822               Started container external-dns
17m         Warning   FailedScheduling          pod/hive-566c674cc9-b5878                                  no nodes available to schedule pods
13m         Warning   FailedScheduling          pod/hive-566c674cc9-b5878                                  0/1 nodes are available: 1 node(s) had untolerated taint {node.cloudprovider.kubernetes.io/uninitialized: true}. preemption: 0/1 nodes are available: 1 Preemption is not helpful for scheduling..
13m         Normal    Scheduled                 pod/hive-566c674cc9-b5878                                  Successfully assigned default/hive-566c674cc9-b5878 to ip-10-0-188-41.us-east-2.compute.internal
13m         Normal    Pulling                   pod/hive-566c674cc9-b5878                                  Pulling image "harbor.starburstdata.net/starburstdata/hive:3.1.3-e.2"
12m         Normal    Pulled                    pod/hive-566c674cc9-b5878                                  Successfully pulled image "harbor.starburstdata.net/starburstdata/hive:3.1.3-e.2" in 40.582645069s (40.582655059s including waiting)
12m         Normal    Created                   pod/hive-566c674cc9-b5878                                  Created container hive
12m         Normal    Started                   pod/hive-566c674cc9-b5878                                  Started container hive
10m         Warning   Unhealthy                 pod/hive-566c674cc9-b5878                                  Liveness probe failed: dial tcp 10.0.188.151:9083: connect: connection refused
13m         Normal    Starting                  node/ip-10-0-179-155.us-east-2.compute.internal            Starting kubelet.
13m         Warning   InvalidDiskCapacity       node/ip-10-0-179-155.us-east-2.compute.internal            invalid capacity 0 on image filesystem
13m         Normal    NodeHasSufficientMemory   node/ip-10-0-179-155.us-east-2.compute.internal            Node ip-10-0-179-155.us-east-2.compute.internal status is now: NodeHasSufficientMemory
13m         Normal    NodeHasNoDiskPressure     node/ip-10-0-179-155.us-east-2.compute.internal            Node ip-10-0-179-155.us-east-2.compute.internal status is now: NodeHasNoDiskPressure
13m         Normal    NodeHasSufficientPID      node/ip-10-0-179-155.us-east-2.compute.internal            Node ip-10-0-179-155.us-east-2.compute.internal status is now: NodeHasSufficientPID
13m         Normal    NodeAllocatableEnforced   node/ip-10-0-179-155.us-east-2.compute.internal            Updated Node Allocatable limit across pods
13m         Normal    Synced                    node/ip-10-0-179-155.us-east-2.compute.internal            Node synced successfully
13m         Normal    RegisteredNode            node/ip-10-0-179-155.us-east-2.compute.internal            Node ip-10-0-179-155.us-east-2.compute.internal event: Registered Node ip-10-0-179-155.us-east-2.compute.internal in Controller
13m         Normal    Starting                  node/ip-10-0-179-155.us-east-2.compute.internal            
13m         Normal    NodeReady                 node/ip-10-0-179-155.us-east-2.compute.internal            Node ip-10-0-179-155.us-east-2.compute.internal status is now: NodeReady
13m         Normal    Starting                  node/ip-10-0-185-3.us-east-2.compute.internal              Starting kubelet.
13m         Warning   InvalidDiskCapacity       node/ip-10-0-185-3.us-east-2.compute.internal              invalid capacity 0 on image filesystem
13m         Normal    NodeHasSufficientMemory   node/ip-10-0-185-3.us-east-2.compute.internal              Node ip-10-0-185-3.us-east-2.compute.internal status is now: NodeHasSufficientMemory
13m         Normal    NodeHasNoDiskPressure     node/ip-10-0-185-3.us-east-2.compute.internal              Node ip-10-0-185-3.us-east-2.compute.internal status is now: NodeHasNoDiskPressure
13m         Normal    NodeHasSufficientPID      node/ip-10-0-185-3.us-east-2.compute.internal              Node ip-10-0-185-3.us-east-2.compute.internal status is now: NodeHasSufficientPID
13m         Normal    NodeAllocatableEnforced   node/ip-10-0-185-3.us-east-2.compute.internal              Updated Node Allocatable limit across pods
13m         Normal    Synced                    node/ip-10-0-185-3.us-east-2.compute.internal              Node synced successfully
13m         Normal    RegisteredNode            node/ip-10-0-185-3.us-east-2.compute.internal              Node ip-10-0-185-3.us-east-2.compute.internal event: Registered Node ip-10-0-185-3.us-east-2.compute.internal in Controller
13m         Normal    Starting                  node/ip-10-0-185-3.us-east-2.compute.internal              
13m         Normal    NodeReady                 node/ip-10-0-185-3.us-east-2.compute.internal              Node ip-10-0-185-3.us-east-2.compute.internal status is now: NodeReady
13m         Normal    Starting                  node/ip-10-0-188-41.us-east-2.compute.internal             Starting kubelet.
13m         Warning   InvalidDiskCapacity       node/ip-10-0-188-41.us-east-2.compute.internal             invalid capacity 0 on image filesystem
13m         Normal    NodeHasSufficientMemory   node/ip-10-0-188-41.us-east-2.compute.internal             Node ip-10-0-188-41.us-east-2.compute.internal status is now: NodeHasSufficientMemory
13m         Normal    NodeHasNoDiskPressure     node/ip-10-0-188-41.us-east-2.compute.internal             Node ip-10-0-188-41.us-east-2.compute.internal status is now: NodeHasNoDiskPressure
13m         Normal    NodeHasSufficientPID      node/ip-10-0-188-41.us-east-2.compute.internal             Node ip-10-0-188-41.us-east-2.compute.internal status is now: NodeHasSufficientPID
13m         Normal    NodeAllocatableEnforced   node/ip-10-0-188-41.us-east-2.compute.internal             Updated Node Allocatable limit across pods
13m         Normal    Synced                    node/ip-10-0-188-41.us-east-2.compute.internal             Node synced successfully
13m         Normal    RegisteredNode            node/ip-10-0-188-41.us-east-2.compute.internal             Node ip-10-0-188-41.us-east-2.compute.internal event: Registered Node ip-10-0-188-41.us-east-2.compute.internal in Controller
13m         Normal    Starting                  node/ip-10-0-188-41.us-east-2.compute.internal             
13m         Normal    NodeReady                 node/ip-10-0-188-41.us-east-2.compute.internal             Node ip-10-0-188-41.us-east-2.compute.internal status is now: NodeReady
17m         Warning   FailedScheduling          pod/nginx-ingress-nginx-controller-6547cdd79b-lbt69        no nodes available to schedule pods
13m         Warning   FailedScheduling          pod/nginx-ingress-nginx-controller-6547cdd79b-lbt69        0/1 nodes are available: 1 node(s) had untolerated taint {node.cloudprovider.kubernetes.io/uninitialized: true}. preemption: 0/1 nodes are available: 1 Preemption is not helpful for scheduling..
13m         Normal    Scheduled                 pod/nginx-ingress-nginx-controller-6547cdd79b-lbt69        Successfully assigned default/nginx-ingress-nginx-controller-6547cdd79b-lbt69 to ip-10-0-188-41.us-east-2.compute.internal
13m         Normal    Pulling                   pod/nginx-ingress-nginx-controller-6547cdd79b-lbt69        Pulling image "registry.k8s.io/ingress-nginx/controller:v1.7.0@sha256:7612338342a1e7b8090bef78f2a04fffcadd548ccaabe8a47bf7758ff549a5f7"
12m         Normal    Pulled                    pod/nginx-ingress-nginx-controller-6547cdd79b-lbt69        Successfully pulled image "registry.k8s.io/ingress-nginx/controller:v1.7.0@sha256:7612338342a1e7b8090bef78f2a04fffcadd548ccaabe8a47bf7758ff549a5f7" in 28.106255187s (28.106266408s including waiting)
12m         Normal    Created                   pod/nginx-ingress-nginx-controller-6547cdd79b-lbt69        Created container controller
12m         Normal    Started                   pod/nginx-ingress-nginx-controller-6547cdd79b-lbt69        Started container controller
12m         Normal    RELOAD                    pod/nginx-ingress-nginx-controller-6547cdd79b-lbt69        NGINX reload triggered due to a change in configuration
13m         Normal    UpdatedLoadBalancer       service/nginx-ingress-nginx-controller                     Updated load balancer with new hosts
12m         Normal    CREATE                    configmap/nginx-ingress-nginx-controller                   ConfigMap default/nginx-ingress-nginx-controller
17m         Warning   FailedScheduling          pod/ranger-7855c458d8-kt2qk                                no nodes available to schedule pods
13m         Warning   FailedScheduling          pod/ranger-7855c458d8-kt2qk                                0/1 nodes are available: 1 node(s) had untolerated taint {node.cloudprovider.kubernetes.io/uninitialized: true}. preemption: 0/1 nodes are available: 1 Preemption is not helpful for scheduling..
13m         Normal    Scheduled                 pod/ranger-7855c458d8-kt2qk                                Successfully assigned default/ranger-7855c458d8-kt2qk to ip-10-0-188-41.us-east-2.compute.internal
13m         Normal    Pulling                   pod/ranger-7855c458d8-kt2qk                                Pulling image "harbor.starburstdata.net/starburstdata/starburst-ranger-admin:2.3.0-e.5"
12m         Normal    Pulled                    pod/ranger-7855c458d8-kt2qk                                Successfully pulled image "harbor.starburstdata.net/starburstdata/starburst-ranger-admin:2.3.0-e.5" in 42.616282654s (42.616308973s including waiting)
10m         Normal    Created                   pod/ranger-7855c458d8-kt2qk                                Created container ranger-admin
10m         Normal    Started                   pod/ranger-7855c458d8-kt2qk                                Started container ranger-admin
10m         Warning   Unhealthy                 pod/ranger-7855c458d8-kt2qk                                Startup probe failed: grep: /opt/ranger/starburst-ranger-server-admin-*/ews/logs/start.sh.log: No such file or directory
10m         Normal    Pulled                    pod/ranger-7855c458d8-kt2qk                                Container image "harbor.starburstdata.net/starburstdata/starburst-ranger-admin:2.3.0-e.5" already present on machine
10m         Warning   BackOff                   pod/ranger-7855c458d8-kt2qk                                Back-off restarting failed container ranger-admin in pod ranger-7855c458d8-kt2qk_default(c3b90db2-8cb6-434e-9928-24e52033b457)
13m         Normal    UpdatedLoadBalancer       service/ranger                                             Updated load balancer with new hosts
13m         Warning   FailedGetResourceMetric   horizontalpodautoscaler/starburst-worker-hpa               failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server is currently unable to handle the request (get pods.metrics.k8s.io)
13m         Normal    UpdatedLoadBalancer       service/starburst                                          Updated load balancer with new hosts
17m         Warning   FailedScheduling          pod/worker-5d58dd7855-7wclj                                no nodes available to schedule pods
13m         Warning   FailedScheduling          pod/worker-5d58dd7855-7wclj                                0/1 nodes are available: 1 node(s) had untolerated taint {node.cloudprovider.kubernetes.io/uninitialized: true}. preemption: 0/1 nodes are available: 1 Preemption is not helpful for scheduling..
13m         Normal    Scheduled                 pod/worker-5d58dd7855-7wclj                                Successfully assigned default/worker-5d58dd7855-7wclj to ip-10-0-185-3.us-east-2.compute.internal
13m         Normal    Pulling                   pod/worker-5d58dd7855-7wclj                                Pulling image "harbor.starburstdata.net/starburstdata/starburst-enterprise-init:1.5.2"
13m         Normal    Pulled                    pod/worker-5d58dd7855-7wclj                                Successfully pulled image "harbor.starburstdata.net/starburstdata/starburst-enterprise-init:1.5.2" in 8.729209176s (8.729237297s including waiting)
13m         Normal    Created                   pod/worker-5d58dd7855-7wclj                                Created container starburst-enterprise-init
13m         Normal    Started                   pod/worker-5d58dd7855-7wclj                                Started container starburst-enterprise-init
12m         Normal    Pulling                   pod/worker-5d58dd7855-7wclj                                Pulling image "harbor.starburstdata.net/starburstdata/starburst-enterprise:423-e.1"
12m         Normal    Pulled                    pod/worker-5d58dd7855-7wclj                                Successfully pulled image "harbor.starburstdata.net/starburstdata/starburst-enterprise:423-e.1" in 42.165108294s (42.165119934s including waiting)
12m         Normal    Created                   pod/worker-5d58dd7855-7wclj                                Created container worker
12m         Normal    Started                   pod/worker-5d58dd7855-7wclj                                Started container worker
12m         Warning   Unhealthy                 pod/worker-5d58dd7855-7wclj                                Startup probe failed: Get "http://10.0.182.151:8080/v1/readiness": dial tcp 10.0.182.151:8080: connect: connection refused
11m         Warning   Unhealthy                 pod/worker-5d58dd7855-7wclj                                Startup probe failed: Get "http://10.0.182.151:8080/v1/readiness": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
11m         Warning   Unhealthy                 pod/worker-5d58dd7855-7wclj                                Startup probe failed: HTTP probe failed with statuscode: 503
